12:40:07 Fold 1/6: --------------------------------

12:40:07 Training model --------------------------------
12:40:09 Epoch 1/200, Training Loss: 14.9696
12:40:09 Epoch 2/200, Training Loss: 6.1512
12:40:09 Epoch 3/200, Training Loss: 3.9534
12:40:09 Epoch 4/200, Training Loss: 3.0393
12:40:09 Epoch 5/200, Training Loss: 2.8055
12:40:09 Epoch 6/200, Training Loss: 2.2159
12:40:09 Epoch 7/200, Training Loss: 2.0879
12:40:09 Epoch 8/200, Training Loss: 1.8789
12:40:09 Epoch 9/200, Training Loss: 1.7619
12:40:09 Epoch 10/200, Training Loss: 1.6947
12:40:10 Epoch 11/200, Training Loss: 1.6405
12:40:10 Epoch 12/200, Training Loss: 1.6108
12:40:10 Epoch 13/200, Training Loss: 1.5876
12:40:10 Epoch 14/200, Training Loss: 1.5738
12:40:10 Epoch 15/200, Training Loss: 1.5616
12:40:10 Epoch 16/200, Training Loss: 1.5553
12:40:10 Epoch 17/200, Training Loss: 1.5469
12:40:10 Epoch 18/200, Training Loss: 1.5433
12:40:10 Epoch 19/200, Training Loss: 1.5373
12:40:10 Epoch 20/200, Training Loss: 1.5339
12:40:10 Epoch 21/200, Training Loss: 1.53
12:40:10 Epoch 22/200, Training Loss: 1.5273
12:40:10 Epoch 23/200, Training Loss: 1.5252
12:40:11 Epoch 24/200, Training Loss: 1.523
12:40:11 Epoch 25/200, Training Loss: 1.5211
12:40:11 Epoch 26/200, Training Loss: 1.52
12:40:11 Epoch 27/200, Training Loss: 1.5169
12:40:11 Epoch 28/200, Training Loss: 1.5151
12:40:11 Epoch 29/200, Training Loss: 1.5142
12:40:11 Epoch 30/200, Training Loss: 1.5123
12:40:11 Epoch 31/200, Training Loss: 1.5107
12:40:11 Epoch 32/200, Training Loss: 1.5093
12:40:11 Epoch 33/200, Training Loss: 1.507
12:40:11 Epoch 34/200, Training Loss: 1.5054
12:40:11 Epoch 35/200, Training Loss: 1.5043
12:40:12 Epoch 36/200, Training Loss: 1.5029
12:40:12 Epoch 37/200, Training Loss: 1.5007
12:40:12 Epoch 38/200, Training Loss: 1.4997
12:40:12 Epoch 39/200, Training Loss: 1.4985
12:40:12 Epoch 40/200, Training Loss: 1.4965
12:40:12 Epoch 41/200, Training Loss: 1.4954
12:40:12 Epoch 42/200, Training Loss: 1.4938
12:40:12 Epoch 43/200, Training Loss: 1.4922
12:40:12 Epoch 44/200, Training Loss: 1.4917
12:40:12 Epoch 45/200, Training Loss: 1.4908
12:40:12 Epoch 46/200, Training Loss: 1.4885
12:40:12 Epoch 47/200, Training Loss: 1.4873
12:40:13 Epoch 48/200, Training Loss: 1.4858
12:40:13 Epoch 49/200, Training Loss: 1.484
12:40:13 Epoch 50/200, Training Loss: 1.4834
12:40:13 Epoch 51/200, Training Loss: 1.4826
12:40:13 Epoch 52/200, Training Loss: 1.4806
12:40:13 Epoch 53/200, Training Loss: 1.4799
12:40:13 Epoch 54/200, Training Loss: 1.4786
12:40:13 Epoch 55/200, Training Loss: 1.4766
12:40:13 Epoch 56/200, Training Loss: 1.476
12:40:13 Epoch 57/200, Training Loss: 1.4754
12:40:13 Epoch 58/200, Training Loss: 1.4736
12:40:14 Epoch 59/200, Training Loss: 1.4727
12:40:14 Epoch 60/200, Training Loss: 1.4709
12:40:14 Epoch 61/200, Training Loss: 1.4688
12:40:14 Epoch 62/200, Training Loss: 1.4686
12:40:14 Epoch 63/200, Training Loss: 1.4683
12:40:14 Epoch 64/200, Training Loss: 1.4665
12:40:14 Epoch 65/200, Training Loss: 1.466
12:40:14 Epoch 66/200, Training Loss: 1.4636
12:40:14 Epoch 67/200, Training Loss: 1.4616
12:40:14 Epoch 68/200, Training Loss: 1.461
12:40:14 Epoch 69/200, Training Loss: 1.4607
12:40:15 Epoch 70/200, Training Loss: 1.4596
12:40:15 Epoch 71/200, Training Loss: 1.4586
12:40:15 Epoch 72/200, Training Loss: 1.4561
12:40:15 Epoch 73/200, Training Loss: 1.4545
12:40:15 Epoch 74/200, Training Loss: 1.4538
12:40:15 Epoch 75/200, Training Loss: 1.4536
12:40:15 Epoch 76/200, Training Loss: 1.4528
12:40:15 Epoch 77/200, Training Loss: 1.4506
12:40:15 Epoch 78/200, Training Loss: 1.4493
12:40:15 Epoch 79/200, Training Loss: 1.4478
12:40:16 Epoch 80/200, Training Loss: 1.4465
12:40:16 Epoch 81/200, Training Loss: 1.4459
12:40:16 Epoch 82/200, Training Loss: 1.445
12:40:16 Epoch 83/200, Training Loss: 1.4432
12:40:16 Epoch 84/200, Training Loss: 1.4422
12:40:16 Epoch 85/200, Training Loss: 1.4411
12:40:16 Epoch 86/200, Training Loss: 1.4394
12:40:16 Epoch 87/200, Training Loss: 1.4383
12:40:16 Epoch 88/200, Training Loss: 1.437
12:40:16 Epoch 89/200, Training Loss: 1.4353
12:40:16 Epoch 90/200, Training Loss: 1.4353
12:40:17 Epoch 91/200, Training Loss: 1.4333
12:40:17 Epoch 92/200, Training Loss: 1.4312
12:40:17 Epoch 93/200, Training Loss: 1.4305
12:40:17 Epoch 94/200, Training Loss: 1.4295
12:40:17 Epoch 95/200, Training Loss: 1.4287
12:40:17 Epoch 96/200, Training Loss: 1.4275
12:40:17 Epoch 97/200, Training Loss: 1.4255
12:40:17 Epoch 98/200, Training Loss: 1.424
12:40:17 Epoch 99/200, Training Loss: 1.4234
12:40:17 Epoch 100/200, Training Loss: 1.4222
12:40:18 Epoch 101/200, Training Loss: 1.4208
12:40:18 Epoch 102/200, Training Loss: 1.4193
12:40:18 Epoch 103/200, Training Loss: 1.4183
12:40:18 Epoch 104/200, Training Loss: 1.4168
12:40:18 Epoch 105/200, Training Loss: 1.4155
12:40:18 Epoch 106/200, Training Loss: 1.4142
12:40:18 Epoch 107/200, Training Loss: 1.4133
12:40:18 Epoch 108/200, Training Loss: 1.4116
12:40:18 Epoch 109/200, Training Loss: 1.4103
12:40:18 Epoch 110/200, Training Loss: 1.4086
12:40:19 Epoch 111/200, Training Loss: 1.4068
12:40:19 Epoch 112/200, Training Loss: 1.4057
12:40:19 Epoch 113/200, Training Loss: 1.4047
12:40:19 Epoch 114/200, Training Loss: 1.4032
12:40:19 Epoch 115/200, Training Loss: 1.4026
12:40:19 Epoch 116/200, Training Loss: 1.4002
12:40:19 Epoch 117/200, Training Loss: 1.3984
12:40:19 Epoch 118/200, Training Loss: 1.398
12:40:19 Epoch 119/200, Training Loss: 1.3972
12:40:19 Epoch 120/200, Training Loss: 1.396
12:40:20 Epoch 121/200, Training Loss: 1.3945
12:40:20 Epoch 122/200, Training Loss: 1.3922
12:40:20 Epoch 123/200, Training Loss: 1.3906
12:40:20 Epoch 124/200, Training Loss: 1.3893
12:40:20 Epoch 125/200, Training Loss: 1.3885
12:40:20 Epoch 126/200, Training Loss: 1.3882
12:40:20 Epoch 127/200, Training Loss: 1.3852
12:40:20 Epoch 128/200, Training Loss: 1.3839
12:40:20 Epoch 129/200, Training Loss: 1.3822
12:40:20 Epoch 130/200, Training Loss: 1.381
12:40:21 Epoch 131/200, Training Loss: 1.3804
12:40:21 Epoch 132/200, Training Loss: 1.3788
12:40:21 Epoch 133/200, Training Loss: 1.3769
12:40:21 Epoch 134/200, Training Loss: 1.3764
12:40:21 Epoch 135/200, Training Loss: 1.3741
12:40:21 Epoch 136/200, Training Loss: 1.3719
12:40:21 Epoch 137/200, Training Loss: 1.3709
12:40:21 Epoch 138/200, Training Loss: 1.3698
12:40:21 Epoch 139/200, Training Loss: 1.3693
12:40:21 Epoch 140/200, Training Loss: 1.368
12:40:22 Epoch 141/200, Training Loss: 1.3655
12:40:22 Epoch 142/200, Training Loss: 1.364
12:40:22 Epoch 143/200, Training Loss: 1.3628
12:40:22 Epoch 144/200, Training Loss: 1.361
12:40:22 Epoch 145/200, Training Loss: 1.3605
12:40:22 Epoch 146/200, Training Loss: 1.3586
12:40:22 Epoch 147/200, Training Loss: 1.3576
12:40:22 Epoch 148/200, Training Loss: 1.3558
12:40:22 Epoch 149/200, Training Loss: 1.3539
12:40:22 Epoch 150/200, Training Loss: 1.3526
12:40:23 Epoch 151/200, Training Loss: 1.3513
12:40:23 Epoch 152/200, Training Loss: 1.3489
12:40:23 Epoch 153/200, Training Loss: 1.3477
12:40:23 Epoch 154/200, Training Loss: 1.3466
12:40:23 Epoch 155/200, Training Loss: 1.3446
12:40:23 Epoch 156/200, Training Loss: 1.3438
12:40:23 Epoch 157/200, Training Loss: 1.3421
12:40:23 Epoch 158/200, Training Loss: 1.3394
12:40:23 Epoch 159/200, Training Loss: 1.3387
12:40:23 Epoch 160/200, Training Loss: 1.337
12:40:24 Epoch 161/200, Training Loss: 1.3355
12:40:24 Epoch 162/200, Training Loss: 1.335
12:40:24 Epoch 163/200, Training Loss: 1.3326
12:40:24 Epoch 164/200, Training Loss: 1.33
12:40:24 Epoch 165/200, Training Loss: 1.3293
12:40:24 Epoch 166/200, Training Loss: 1.3275
12:40:24 Epoch 167/200, Training Loss: 1.3258
12:40:24 Epoch 168/200, Training Loss: 1.3254
12:40:24 Epoch 169/200, Training Loss: 1.3225
12:40:24 Epoch 170/200, Training Loss: 1.3215
12:40:24 Epoch 171/200, Training Loss: 1.3207
12:40:25 Epoch 172/200, Training Loss: 1.3182
12:40:25 Epoch 173/200, Training Loss: 1.3165
12:40:25 Epoch 174/200, Training Loss: 1.3153
12:40:25 Epoch 175/200, Training Loss: 1.3138
12:40:25 Epoch 176/200, Training Loss: 1.3127
12:40:25 Epoch 177/200, Training Loss: 1.31
12:40:25 Epoch 178/200, Training Loss: 1.3088
12:40:25 Epoch 179/200, Training Loss: 1.3067
12:40:25 Epoch 180/200, Training Loss: 1.3046
12:40:25 Epoch 181/200, Training Loss: 1.3047
12:40:25 Epoch 182/200, Training Loss: 1.3027
12:40:25 Epoch 183/200, Training Loss: 1.3
12:40:26 Epoch 184/200, Training Loss: 1.2987
12:40:26 Epoch 185/200, Training Loss: 1.2968
12:40:26 Epoch 186/200, Training Loss: 1.2948
12:40:26 Epoch 187/200, Training Loss: 1.2949
12:40:26 Epoch 188/200, Training Loss: 1.2919
12:40:26 Epoch 189/200, Training Loss: 1.2903
12:40:26 Epoch 190/200, Training Loss: 1.2893
12:40:26 Epoch 191/200, Training Loss: 1.2864
12:40:26 Epoch 192/200, Training Loss: 1.285
12:40:26 Epoch 193/200, Training Loss: 1.2839
12:40:26 Epoch 194/200, Training Loss: 1.282
12:40:26 Epoch 195/200, Training Loss: 1.2814
12:40:27 Epoch 196/200, Training Loss: 1.2783
12:40:27 Epoch 197/200, Training Loss: 1.277
12:40:27 Epoch 198/200, Training Loss: 1.2753
12:40:27 Epoch 199/200, Training Loss: 1.2731
12:40:27 Epoch 200/200, Training Loss: 1.2728
12:40:27 Model training complete and best model saved --------------------------------

12:40:27 Testing model --------------------------------
12:40:27 Test Loss on this fold: 1.8648
12:40:27 Best model updated from this fold based on test loss.
12:40:27 Model testing complete --------------------------------

12:40:27 Fold 2/6: --------------------------------

12:40:27 Training model --------------------------------
12:40:27 Epoch 1/200, Training Loss: 14.6817
12:40:27 Epoch 2/200, Training Loss: 6.1738
12:40:27 Epoch 3/200, Training Loss: 4.1636
12:40:27 Epoch 4/200, Training Loss: 2.8906
12:40:27 Epoch 5/200, Training Loss: 2.7688
12:40:27 Epoch 6/200, Training Loss: 2.3212
12:40:27 Epoch 7/200, Training Loss: 2.0835
12:40:28 Epoch 8/200, Training Loss: 1.8861
12:40:28 Epoch 9/200, Training Loss: 1.7541
12:40:28 Epoch 10/200, Training Loss: 1.6801
12:40:28 Epoch 11/200, Training Loss: 1.6345
12:40:28 Epoch 12/200, Training Loss: 1.6115
12:40:28 Epoch 13/200, Training Loss: 1.5788
12:40:29 Epoch 14/200, Training Loss: 1.5694
12:40:30 Epoch 15/200, Training Loss: 1.555
12:40:31 Epoch 16/200, Training Loss: 1.5461
12:40:32 Epoch 17/200, Training Loss: 1.5372
12:40:33 Epoch 18/200, Training Loss: 1.5333
12:40:34 Epoch 19/200, Training Loss: 1.527
12:40:36 Epoch 20/200, Training Loss: 1.5236
12:40:37 Epoch 21/200, Training Loss: 1.5191
12:40:38 Epoch 22/200, Training Loss: 1.5163
12:40:39 Epoch 23/200, Training Loss: 1.513
12:40:40 Epoch 24/200, Training Loss: 1.5105
12:40:41 Epoch 25/200, Training Loss: 1.5079
12:40:42 Epoch 26/200, Training Loss: 1.5058
12:40:43 Epoch 27/200, Training Loss: 1.5038
12:40:45 Epoch 28/200, Training Loss: 1.5013
12:40:46 Epoch 29/200, Training Loss: 1.4994
12:40:47 Epoch 30/200, Training Loss: 1.4976
12:40:48 Epoch 31/200, Training Loss: 1.4954
12:40:49 Epoch 32/200, Training Loss: 1.4937
12:40:50 Epoch 33/200, Training Loss: 1.4923
12:40:51 Epoch 34/200, Training Loss: 1.4904
12:40:52 Epoch 35/200, Training Loss: 1.4892
12:40:53 Epoch 36/200, Training Loss: 1.4873
12:40:54 Epoch 37/200, Training Loss: 1.4855
12:40:55 Epoch 38/200, Training Loss: 1.4843
12:40:56 Epoch 39/200, Training Loss: 1.4821
12:40:56 Epoch 40/200, Training Loss: 1.4805
12:40:57 Epoch 41/200, Training Loss: 1.4796
12:40:58 Epoch 42/200, Training Loss: 1.4772
12:40:59 Epoch 43/200, Training Loss: 1.4762
12:40:59 Epoch 44/200, Training Loss: 1.4747
12:41:00 Epoch 45/200, Training Loss: 1.473
12:41:00 Epoch 46/200, Training Loss: 1.4718
12:41:00 Epoch 47/200, Training Loss: 1.4702
12:41:01 Epoch 48/200, Training Loss: 1.4682
12:41:01 Epoch 49/200, Training Loss: 1.4668
12:41:01 Epoch 50/200, Training Loss: 1.4652
12:41:01 Epoch 51/200, Training Loss: 1.4636
12:41:02 Epoch 52/200, Training Loss: 1.4623
12:41:02 Epoch 53/200, Training Loss: 1.4608
12:41:02 Epoch 54/200, Training Loss: 1.4595
12:41:03 Epoch 55/200, Training Loss: 1.4579
12:41:03 Epoch 56/200, Training Loss: 1.4565
12:41:04 Epoch 57/200, Training Loss: 1.455
12:41:04 Epoch 58/200, Training Loss: 1.4536
12:41:04 Epoch 59/200, Training Loss: 1.4523
12:41:04 Epoch 60/200, Training Loss: 1.4509
12:41:04 Epoch 61/200, Training Loss: 1.4493
12:41:04 Epoch 62/200, Training Loss: 1.4475
12:41:04 Epoch 63/200, Training Loss: 1.4465
12:41:04 Epoch 64/200, Training Loss: 1.4448
12:41:04 Epoch 65/200, Training Loss: 1.4429
12:41:04 Epoch 66/200, Training Loss: 1.4421
12:41:05 Epoch 67/200, Training Loss: 1.4406
12:41:05 Epoch 68/200, Training Loss: 1.4386
12:41:05 Epoch 69/200, Training Loss: 1.4378
12:41:05 Epoch 70/200, Training Loss: 1.4362
12:41:05 Epoch 71/200, Training Loss: 1.434
12:41:05 Epoch 72/200, Training Loss: 1.4331
12:41:05 Epoch 73/200, Training Loss: 1.4317
12:41:05 Epoch 74/200, Training Loss: 1.4297
12:41:05 Epoch 75/200, Training Loss: 1.4293
12:41:05 Epoch 76/200, Training Loss: 1.4273
12:41:05 Epoch 77/200, Training Loss: 1.4254
12:41:05 Epoch 78/200, Training Loss: 1.4244
12:41:05 Epoch 79/200, Training Loss: 1.423
12:41:05 Epoch 80/200, Training Loss: 1.4209
12:41:06 Epoch 81/200, Training Loss: 1.4199
12:41:06 Epoch 82/200, Training Loss: 1.4189
12:41:06 Epoch 83/200, Training Loss: 1.4167
12:41:06 Epoch 84/200, Training Loss: 1.4163
12:41:06 Epoch 85/200, Training Loss: 1.4143
12:41:06 Epoch 86/200, Training Loss: 1.4123
12:41:06 Epoch 87/200, Training Loss: 1.4106
12:41:06 Epoch 88/200, Training Loss: 1.4093
12:41:06 Epoch 89/200, Training Loss: 1.4078
12:41:06 Epoch 90/200, Training Loss: 1.4079
12:41:06 Epoch 91/200, Training Loss: 1.4057
12:41:06 Epoch 92/200, Training Loss: 1.4033
12:41:06 Epoch 93/200, Training Loss: 1.4023
12:41:06 Epoch 94/200, Training Loss: 1.4005
12:41:07 Epoch 95/200, Training Loss: 1.3983
12:41:07 Epoch 96/200, Training Loss: 1.398
12:41:07 Epoch 97/200, Training Loss: 1.3969
12:41:07 Epoch 98/200, Training Loss: 1.3941
12:41:07 Epoch 99/200, Training Loss: 1.3932
12:41:07 Epoch 100/200, Training Loss: 1.3912
12:41:07 Epoch 101/200, Training Loss: 1.3896
12:41:07 Epoch 102/200, Training Loss: 1.3882
12:41:07 Epoch 103/200, Training Loss: 1.3873
12:41:07 Epoch 104/200, Training Loss: 1.385
12:41:07 Epoch 105/200, Training Loss: 1.3834
12:41:07 Epoch 106/200, Training Loss: 1.3822
12:41:07 Epoch 107/200, Training Loss: 1.3799
12:41:07 Epoch 108/200, Training Loss: 1.3791
12:41:07 Epoch 109/200, Training Loss: 1.3778
12:41:08 Epoch 110/200, Training Loss: 1.3755
12:41:08 Epoch 111/200, Training Loss: 1.3736
12:41:08 Epoch 112/200, Training Loss: 1.372
12:41:08 Epoch 113/200, Training Loss: 1.3707
12:41:08 Epoch 114/200, Training Loss: 1.3688
12:41:08 Epoch 115/200, Training Loss: 1.3678
12:41:08 Epoch 116/200, Training Loss: 1.3655
12:41:08 Epoch 117/200, Training Loss: 1.3648
12:41:08 Epoch 118/200, Training Loss: 1.3625
12:41:08 Epoch 119/200, Training Loss: 1.3602
12:41:08 Epoch 120/200, Training Loss: 1.359
12:41:08 Epoch 121/200, Training Loss: 1.3581
12:41:09 Epoch 122/200, Training Loss: 1.3557
12:41:09 Epoch 123/200, Training Loss: 1.3546
12:41:09 Epoch 124/200, Training Loss: 1.3525
12:41:09 Epoch 125/200, Training Loss: 1.35
12:41:09 Epoch 126/200, Training Loss: 1.3485
12:41:09 Epoch 127/200, Training Loss: 1.3472
12:41:09 Epoch 128/200, Training Loss: 1.345
12:41:09 Epoch 129/200, Training Loss: 1.345
12:41:09 Epoch 130/200, Training Loss: 1.3424
12:41:09 Epoch 131/200, Training Loss: 1.3397
12:41:09 Epoch 132/200, Training Loss: 1.3386
12:41:09 Epoch 133/200, Training Loss: 1.337
12:41:10 Epoch 134/200, Training Loss: 1.3349
12:41:10 Epoch 135/200, Training Loss: 1.3329
12:41:10 Epoch 136/200, Training Loss: 1.3321
12:41:10 Epoch 137/200, Training Loss: 1.3291
12:41:10 Epoch 138/200, Training Loss: 1.3273
12:41:10 Epoch 139/200, Training Loss: 1.3254
12:41:10 Epoch 140/200, Training Loss: 1.3236
12:41:10 Epoch 141/200, Training Loss: 1.3225
12:41:10 Epoch 142/200, Training Loss: 1.3212
12:41:10 Epoch 143/200, Training Loss: 1.3188
12:41:10 Epoch 144/200, Training Loss: 1.3165
12:41:11 Epoch 145/200, Training Loss: 1.3148
12:41:11 Epoch 146/200, Training Loss: 1.3134
12:41:11 Epoch 147/200, Training Loss: 1.311
12:41:11 Epoch 148/200, Training Loss: 1.3098
12:41:11 Epoch 149/200, Training Loss: 1.3071
12:41:11 Epoch 150/200, Training Loss: 1.3055
12:41:11 Epoch 151/200, Training Loss: 1.3037
12:41:11 Epoch 152/200, Training Loss: 1.3016
12:41:11 Epoch 153/200, Training Loss: 1.2999
12:41:11 Epoch 154/200, Training Loss: 1.2984
12:41:11 Epoch 155/200, Training Loss: 1.2959
12:41:12 Epoch 156/200, Training Loss: 1.2936
12:41:12 Epoch 157/200, Training Loss: 1.2918
12:41:12 Epoch 158/200, Training Loss: 1.2905
12:41:12 Epoch 159/200, Training Loss: 1.2887
12:41:12 Epoch 160/200, Training Loss: 1.2869
12:41:12 Epoch 161/200, Training Loss: 1.2846
12:41:12 Epoch 162/200, Training Loss: 1.2817
12:41:12 Epoch 163/200, Training Loss: 1.2801
12:41:12 Epoch 164/200, Training Loss: 1.2787
12:41:12 Epoch 165/200, Training Loss: 1.276
12:41:13 Epoch 166/200, Training Loss: 1.2745
12:41:13 Epoch 167/200, Training Loss: 1.2728
12:41:13 Epoch 168/200, Training Loss: 1.2699
12:41:13 Epoch 169/200, Training Loss: 1.2682
12:41:13 Epoch 170/200, Training Loss: 1.2659
12:41:13 Epoch 171/200, Training Loss: 1.2638
12:41:13 Epoch 172/200, Training Loss: 1.2625
12:41:13 Epoch 173/200, Training Loss: 1.2609
12:41:13 Epoch 174/200, Training Loss: 1.2585
12:41:13 Epoch 175/200, Training Loss: 1.2567
12:41:13 Epoch 176/200, Training Loss: 1.2542
12:41:14 Epoch 177/200, Training Loss: 1.2517
12:41:14 Epoch 178/200, Training Loss: 1.2496
12:41:14 Epoch 179/200, Training Loss: 1.2491
12:41:14 Epoch 180/200, Training Loss: 1.2468
12:41:14 Epoch 181/200, Training Loss: 1.2453
12:41:14 Epoch 182/200, Training Loss: 1.242
12:41:14 Epoch 183/200, Training Loss: 1.2391
12:41:14 Epoch 184/200, Training Loss: 1.237
12:41:14 Epoch 185/200, Training Loss: 1.2362
12:41:14 Epoch 186/200, Training Loss: 1.2345
12:41:14 Epoch 187/200, Training Loss: 1.2338
12:41:15 Epoch 188/200, Training Loss: 1.2304
12:41:15 Epoch 189/200, Training Loss: 1.2273
12:41:15 Epoch 190/200, Training Loss: 1.2247
12:41:15 Epoch 191/200, Training Loss: 1.2228
12:41:15 Epoch 192/200, Training Loss: 1.2213
12:41:15 Epoch 193/200, Training Loss: 1.2191
12:41:15 Epoch 194/200, Training Loss: 1.2186
12:41:15 Epoch 195/200, Training Loss: 1.215
12:41:15 Epoch 196/200, Training Loss: 1.2123
12:41:15 Epoch 197/200, Training Loss: 1.2109
12:41:15 Epoch 198/200, Training Loss: 1.2083
12:41:16 Epoch 199/200, Training Loss: 1.2063
12:41:16 Epoch 200/200, Training Loss: 1.2055
12:41:16 Model training complete and best model saved --------------------------------

12:41:16 Testing model --------------------------------
12:41:16 Test Loss on this fold: 1.9292
12:41:16 Model testing complete --------------------------------

12:41:16 Fold 3/6: --------------------------------

12:41:16 Training model --------------------------------
12:41:16 Epoch 1/200, Training Loss: 14.0069
12:41:16 Epoch 2/200, Training Loss: 5.673
12:41:16 Epoch 3/200, Training Loss: 3.6628
12:41:16 Epoch 4/200, Training Loss: 2.7446
12:41:16 Epoch 5/200, Training Loss: 2.6694
12:41:16 Epoch 6/200, Training Loss: 2.3766
12:41:16 Epoch 7/200, Training Loss: 1.9552
12:41:16 Epoch 8/200, Training Loss: 1.8276
12:41:16 Epoch 9/200, Training Loss: 1.6298
12:41:17 Epoch 10/200, Training Loss: 1.5788
12:41:17 Epoch 11/200, Training Loss: 1.5064
12:41:17 Epoch 12/200, Training Loss: 1.4865
12:41:17 Epoch 13/200, Training Loss: 1.4566
12:41:17 Epoch 14/200, Training Loss: 1.4488
12:41:17 Epoch 15/200, Training Loss: 1.4277
12:41:17 Epoch 16/200, Training Loss: 1.422
12:41:17 Epoch 17/200, Training Loss: 1.4131
12:41:17 Epoch 18/200, Training Loss: 1.4077
12:41:17 Epoch 19/200, Training Loss: 1.4011
12:41:17 Epoch 20/200, Training Loss: 1.3983
12:41:17 Epoch 21/200, Training Loss: 1.393
12:41:18 Epoch 22/200, Training Loss: 1.3906
12:41:18 Epoch 23/200, Training Loss: 1.3871
12:41:18 Epoch 24/200, Training Loss: 1.3852
12:41:18 Epoch 25/200, Training Loss: 1.3829
12:41:18 Epoch 26/200, Training Loss: 1.3808
12:41:18 Epoch 27/200, Training Loss: 1.3788
12:41:18 Epoch 28/200, Training Loss: 1.3766
12:41:18 Epoch 29/200, Training Loss: 1.3753
12:41:18 Epoch 30/200, Training Loss: 1.3732
12:41:18 Epoch 31/200, Training Loss: 1.3714
12:41:18 Epoch 32/200, Training Loss: 1.3705
12:41:18 Epoch 33/200, Training Loss: 1.3682
12:41:19 Epoch 34/200, Training Loss: 1.3671
12:41:19 Epoch 35/200, Training Loss: 1.3663
12:41:19 Epoch 36/200, Training Loss: 1.3636
12:41:19 Epoch 37/200, Training Loss: 1.3627
12:41:19 Epoch 38/200, Training Loss: 1.3609
12:41:19 Epoch 39/200, Training Loss: 1.3594
12:41:19 Epoch 40/200, Training Loss: 1.3588
12:41:19 Epoch 41/200, Training Loss: 1.3566
12:41:19 Epoch 42/200, Training Loss: 1.3556
12:41:19 Epoch 43/200, Training Loss: 1.3545
12:41:19 Epoch 44/200, Training Loss: 1.3521
12:41:19 Epoch 45/200, Training Loss: 1.3512
12:41:20 Epoch 46/200, Training Loss: 1.3504
12:41:20 Epoch 47/200, Training Loss: 1.3485
12:41:20 Epoch 48/200, Training Loss: 1.348
12:41:20 Epoch 49/200, Training Loss: 1.3466
12:41:20 Epoch 50/200, Training Loss: 1.3445
12:41:20 Epoch 51/200, Training Loss: 1.3437
12:41:20 Epoch 52/200, Training Loss: 1.3428
12:41:20 Epoch 53/200, Training Loss: 1.3411
12:41:20 Epoch 54/200, Training Loss: 1.3405
12:41:20 Epoch 55/200, Training Loss: 1.3387
12:41:20 Epoch 56/200, Training Loss: 1.3375
12:41:21 Epoch 57/200, Training Loss: 1.3368
12:41:21 Epoch 58/200, Training Loss: 1.335
12:41:21 Epoch 59/200, Training Loss: 1.3342
12:41:21 Epoch 60/200, Training Loss: 1.3336
12:41:21 Epoch 61/200, Training Loss: 1.3312
12:41:21 Epoch 62/200, Training Loss: 1.331
12:41:21 Epoch 63/200, Training Loss: 1.3305
12:41:21 Epoch 64/200, Training Loss: 1.3281
12:41:21 Epoch 65/200, Training Loss: 1.327
12:41:21 Epoch 66/200, Training Loss: 1.3261
12:41:21 Epoch 67/200, Training Loss: 1.325
12:41:21 Epoch 68/200, Training Loss: 1.324
12:41:21 Epoch 69/200, Training Loss: 1.3224
12:41:21 Epoch 70/200, Training Loss: 1.3214
12:41:22 Epoch 71/200, Training Loss: 1.3205
12:41:22 Epoch 72/200, Training Loss: 1.3187
12:41:22 Epoch 73/200, Training Loss: 1.318
12:41:22 Epoch 74/200, Training Loss: 1.3174
12:41:22 Epoch 75/200, Training Loss: 1.3157
12:41:22 Epoch 76/200, Training Loss: 1.315
12:41:22 Epoch 77/200, Training Loss: 1.3139
12:41:22 Epoch 78/200, Training Loss: 1.3116
12:41:22 Epoch 79/200, Training Loss: 1.3108
12:41:22 Epoch 80/200, Training Loss: 1.3105
12:41:22 Epoch 81/200, Training Loss: 1.3086
12:41:22 Epoch 82/200, Training Loss: 1.3082
12:41:22 Epoch 83/200, Training Loss: 1.3072
12:41:22 Epoch 84/200, Training Loss: 1.3046
12:41:23 Epoch 85/200, Training Loss: 1.3042
12:41:23 Epoch 86/200, Training Loss: 1.3033
12:41:23 Epoch 87/200, Training Loss: 1.3018
12:41:23 Epoch 88/200, Training Loss: 1.3007
12:41:23 Epoch 89/200, Training Loss: 1.3
12:41:23 Epoch 90/200, Training Loss: 1.2985
12:41:23 Epoch 91/200, Training Loss: 1.2974
12:41:23 Epoch 92/200, Training Loss: 1.2966
12:41:23 Epoch 93/200, Training Loss: 1.2954
12:41:23 Epoch 94/200, Training Loss: 1.2939
12:41:23 Epoch 95/200, Training Loss: 1.2923
12:41:23 Epoch 96/200, Training Loss: 1.2914
12:41:23 Epoch 97/200, Training Loss: 1.2903
12:41:24 Epoch 98/200, Training Loss: 1.289
12:41:24 Epoch 99/200, Training Loss: 1.2887
12:41:24 Epoch 100/200, Training Loss: 1.2875
12:41:24 Epoch 101/200, Training Loss: 1.285
12:41:24 Epoch 102/200, Training Loss: 1.2845
12:41:24 Epoch 103/200, Training Loss: 1.2835
12:41:24 Epoch 104/200, Training Loss: 1.2814
12:41:24 Epoch 105/200, Training Loss: 1.2808
12:41:24 Epoch 106/200, Training Loss: 1.2799
12:41:24 Epoch 107/200, Training Loss: 1.2785
12:41:25 Epoch 108/200, Training Loss: 1.2783
12:41:26 Epoch 109/200, Training Loss: 1.2765
12:41:27 Epoch 110/200, Training Loss: 1.2741
12:41:28 Epoch 111/200, Training Loss: 1.2731
12:41:29 Epoch 112/200, Training Loss: 1.273
12:41:30 Epoch 113/200, Training Loss: 1.271
12:41:31 Epoch 114/200, Training Loss: 1.2702
12:41:32 Epoch 115/200, Training Loss: 1.2696
12:41:33 Epoch 116/200, Training Loss: 1.2671
12:41:34 Epoch 117/200, Training Loss: 1.2662
12:41:35 Epoch 118/200, Training Loss: 1.2654
12:41:36 Epoch 119/200, Training Loss: 1.2638
12:41:37 Epoch 120/200, Training Loss: 1.2622
12:41:38 Epoch 121/200, Training Loss: 1.2611
12:41:40 Epoch 122/200, Training Loss: 1.2596
12:41:41 Epoch 123/200, Training Loss: 1.2588
12:41:42 Epoch 124/200, Training Loss: 1.2584
12:41:43 Epoch 125/200, Training Loss: 1.2563
12:41:44 Epoch 126/200, Training Loss: 1.2549
12:41:45 Epoch 127/200, Training Loss: 1.2538
12:41:46 Epoch 128/200, Training Loss: 1.2526
12:41:47 Epoch 129/200, Training Loss: 1.2508
12:41:48 Epoch 130/200, Training Loss: 1.2491
12:41:49 Epoch 131/200, Training Loss: 1.2486
12:41:50 Epoch 132/200, Training Loss: 1.2476
12:41:51 Epoch 133/200, Training Loss: 1.2462
12:41:52 Epoch 134/200, Training Loss: 1.2455
12:41:53 Epoch 135/200, Training Loss: 1.2434
12:41:54 Epoch 136/200, Training Loss: 1.2414
12:41:54 Epoch 137/200, Training Loss: 1.2407
12:41:54 Epoch 138/200, Training Loss: 1.2402
12:41:55 Epoch 139/200, Training Loss: 1.2378
12:41:55 Epoch 140/200, Training Loss: 1.2371
12:41:55 Epoch 141/200, Training Loss: 1.236
12:41:55 Epoch 142/200, Training Loss: 1.2338
12:41:55 Epoch 143/200, Training Loss: 1.2327
12:41:55 Epoch 144/200, Training Loss: 1.2318
12:41:55 Epoch 145/200, Training Loss: 1.2295
12:41:55 Epoch 146/200, Training Loss: 1.229
12:41:55 Epoch 147/200, Training Loss: 1.2279
12:41:55 Epoch 148/200, Training Loss: 1.225
12:41:55 Epoch 149/200, Training Loss: 1.2242
12:41:55 Epoch 150/200, Training Loss: 1.2231
12:41:56 Epoch 151/200, Training Loss: 1.2214
12:41:56 Epoch 152/200, Training Loss: 1.2204
12:41:56 Epoch 153/200, Training Loss: 1.2196
12:41:56 Epoch 154/200, Training Loss: 1.2171
12:41:56 Epoch 155/200, Training Loss: 1.2161
12:41:56 Epoch 156/200, Training Loss: 1.2146
12:41:56 Epoch 157/200, Training Loss: 1.2127
12:41:56 Epoch 158/200, Training Loss: 1.2119
12:41:56 Epoch 159/200, Training Loss: 1.2106
12:41:56 Epoch 160/200, Training Loss: 1.2081
12:41:56 Epoch 161/200, Training Loss: 1.2077
12:41:56 Epoch 162/200, Training Loss: 1.2064
12:41:56 Epoch 163/200, Training Loss: 1.2043
12:41:56 Epoch 164/200, Training Loss: 1.2033
12:41:57 Epoch 165/200, Training Loss: 1.2017
12:41:57 Epoch 166/200, Training Loss: 1.1998
12:41:57 Epoch 167/200, Training Loss: 1.199
12:41:57 Epoch 168/200, Training Loss: 1.1971
12:41:57 Epoch 169/200, Training Loss: 1.1951
12:41:57 Epoch 170/200, Training Loss: 1.1947
12:41:57 Epoch 171/200, Training Loss: 1.1927
12:41:57 Epoch 172/200, Training Loss: 1.1908
12:41:57 Epoch 173/200, Training Loss: 1.189
12:41:57 Epoch 174/200, Training Loss: 1.1874
12:41:57 Epoch 175/200, Training Loss: 1.1862
12:41:57 Epoch 176/200, Training Loss: 1.1854
12:41:57 Epoch 177/200, Training Loss: 1.1836
12:41:58 Epoch 178/200, Training Loss: 1.1829
12:41:58 Epoch 179/200, Training Loss: 1.181
12:41:58 Epoch 180/200, Training Loss: 1.179
12:41:58 Epoch 181/200, Training Loss: 1.1772
12:41:58 Epoch 182/200, Training Loss: 1.1765
12:41:58 Epoch 183/200, Training Loss: 1.1744
12:41:58 Epoch 184/200, Training Loss: 1.1727
12:41:58 Epoch 185/200, Training Loss: 1.1712
12:41:58 Epoch 186/200, Training Loss: 1.1694
12:41:58 Epoch 187/200, Training Loss: 1.168
12:41:58 Epoch 188/200, Training Loss: 1.1665
12:41:58 Epoch 189/200, Training Loss: 1.1648
12:41:58 Epoch 190/200, Training Loss: 1.1635
12:41:59 Epoch 191/200, Training Loss: 1.1611
12:41:59 Epoch 192/200, Training Loss: 1.1594
12:41:59 Epoch 193/200, Training Loss: 1.1589
12:41:59 Epoch 194/200, Training Loss: 1.1568
12:41:59 Epoch 195/200, Training Loss: 1.1554
12:41:59 Epoch 196/200, Training Loss: 1.1545
12:41:59 Epoch 197/200, Training Loss: 1.1513
12:41:59 Epoch 198/200, Training Loss: 1.1501
12:41:59 Epoch 199/200, Training Loss: 1.1494
12:41:59 Epoch 200/200, Training Loss: 1.1473
12:41:59 Model training complete and best model saved --------------------------------

12:41:59 Testing model --------------------------------
12:41:59 Test Loss on this fold: 2.9390
12:41:59 Model testing complete --------------------------------

12:41:59 Fold 4/6: --------------------------------

12:41:59 Training model --------------------------------
12:41:59 Epoch 1/200, Training Loss: 14.3895
12:41:59 Epoch 2/200, Training Loss: 6.0089
12:41:59 Epoch 3/200, Training Loss: 4.0111
12:42:00 Epoch 4/200, Training Loss: 2.9551
12:42:00 Epoch 5/200, Training Loss: 2.7681
12:42:00 Epoch 6/200, Training Loss: 2.2384
12:42:00 Epoch 7/200, Training Loss: 2.0606
12:42:00 Epoch 8/200, Training Loss: 1.8791
12:42:00 Epoch 9/200, Training Loss: 1.7419
12:42:00 Epoch 10/200, Training Loss: 1.6818
12:42:00 Epoch 11/200, Training Loss: 1.6249
12:42:00 Epoch 12/200, Training Loss: 1.5978
12:42:00 Epoch 13/200, Training Loss: 1.5694
12:42:00 Epoch 14/200, Training Loss: 1.558
12:42:01 Epoch 15/200, Training Loss: 1.5444
12:42:01 Epoch 16/200, Training Loss: 1.536
12:42:01 Epoch 17/200, Training Loss: 1.5281
12:42:01 Epoch 18/200, Training Loss: 1.5241
12:42:01 Epoch 19/200, Training Loss: 1.5183
12:42:01 Epoch 20/200, Training Loss: 1.5152
12:42:01 Epoch 21/200, Training Loss: 1.5108
12:42:01 Epoch 22/200, Training Loss: 1.5078
12:42:01 Epoch 23/200, Training Loss: 1.5045
12:42:01 Epoch 24/200, Training Loss: 1.5021
12:42:01 Epoch 25/200, Training Loss: 1.4996
12:42:01 Epoch 26/200, Training Loss: 1.497
12:42:02 Epoch 27/200, Training Loss: 1.4948
12:42:02 Epoch 28/200, Training Loss: 1.4929
12:42:02 Epoch 29/200, Training Loss: 1.4908
12:42:02 Epoch 30/200, Training Loss: 1.4889
12:42:02 Epoch 31/200, Training Loss: 1.4868
12:42:02 Epoch 32/200, Training Loss: 1.4851
12:42:02 Epoch 33/200, Training Loss: 1.4836
12:42:02 Epoch 34/200, Training Loss: 1.4821
12:42:02 Epoch 35/200, Training Loss: 1.4798
12:42:02 Epoch 36/200, Training Loss: 1.4781
12:42:02 Epoch 37/200, Training Loss: 1.4766
12:42:03 Epoch 38/200, Training Loss: 1.4746
12:42:03 Epoch 39/200, Training Loss: 1.4732
12:42:03 Epoch 40/200, Training Loss: 1.4715
12:42:03 Epoch 41/200, Training Loss: 1.4693
12:42:03 Epoch 42/200, Training Loss: 1.4679
12:42:03 Epoch 43/200, Training Loss: 1.4663
12:42:03 Epoch 44/200, Training Loss: 1.4645
12:42:03 Epoch 45/200, Training Loss: 1.4631
12:42:03 Epoch 46/200, Training Loss: 1.4611
12:42:03 Epoch 47/200, Training Loss: 1.4599
12:42:03 Epoch 48/200, Training Loss: 1.4585
12:42:04 Epoch 49/200, Training Loss: 1.4567
12:42:04 Epoch 50/200, Training Loss: 1.4552
12:42:04 Epoch 51/200, Training Loss: 1.4541
12:42:04 Epoch 52/200, Training Loss: 1.4524
12:42:04 Epoch 53/200, Training Loss: 1.451
12:42:04 Epoch 54/200, Training Loss: 1.4487
12:42:04 Epoch 55/200, Training Loss: 1.447
12:42:04 Epoch 56/200, Training Loss: 1.4456
12:42:04 Epoch 57/200, Training Loss: 1.4443
12:42:04 Epoch 58/200, Training Loss: 1.4431
12:42:04 Epoch 59/200, Training Loss: 1.4412
12:42:05 Epoch 60/200, Training Loss: 1.4398
12:42:05 Epoch 61/200, Training Loss: 1.4382
12:42:05 Epoch 62/200, Training Loss: 1.4364
12:42:05 Epoch 63/200, Training Loss: 1.4344
12:42:05 Epoch 64/200, Training Loss: 1.4332
12:42:05 Epoch 65/200, Training Loss: 1.4322
12:42:05 Epoch 66/200, Training Loss: 1.4308
12:42:05 Epoch 67/200, Training Loss: 1.4294
12:42:05 Epoch 68/200, Training Loss: 1.4272
12:42:05 Epoch 69/200, Training Loss: 1.4254
12:42:05 Epoch 70/200, Training Loss: 1.4241
12:42:06 Epoch 71/200, Training Loss: 1.4227
12:42:06 Epoch 72/200, Training Loss: 1.4214
12:42:06 Epoch 73/200, Training Loss: 1.4211
12:42:06 Epoch 74/200, Training Loss: 1.4184
12:42:06 Epoch 75/200, Training Loss: 1.4164
12:42:06 Epoch 76/200, Training Loss: 1.415
12:42:06 Epoch 77/200, Training Loss: 1.4136
12:42:06 Epoch 78/200, Training Loss: 1.4126
12:42:06 Epoch 79/200, Training Loss: 1.4107
12:42:06 Epoch 80/200, Training Loss: 1.4096
12:42:06 Epoch 81/200, Training Loss: 1.4075
12:42:07 Epoch 82/200, Training Loss: 1.4063
12:42:07 Epoch 83/200, Training Loss: 1.4045
12:42:07 Epoch 84/200, Training Loss: 1.4033
12:42:07 Epoch 85/200, Training Loss: 1.4011
12:42:07 Epoch 86/200, Training Loss: 1.3997
12:42:07 Epoch 87/200, Training Loss: 1.3989
12:42:07 Epoch 88/200, Training Loss: 1.3968
12:42:07 Epoch 89/200, Training Loss: 1.3954
12:42:07 Epoch 90/200, Training Loss: 1.3939
12:42:07 Epoch 91/200, Training Loss: 1.3916
12:42:07 Epoch 92/200, Training Loss: 1.3897
12:42:08 Epoch 93/200, Training Loss: 1.3888
12:42:08 Epoch 94/200, Training Loss: 1.3873
12:42:08 Epoch 95/200, Training Loss: 1.3861
12:42:08 Epoch 96/200, Training Loss: 1.3849
12:42:08 Epoch 97/200, Training Loss: 1.3825
12:42:08 Epoch 98/200, Training Loss: 1.3805
12:42:08 Epoch 99/200, Training Loss: 1.379
12:42:08 Epoch 100/200, Training Loss: 1.377
12:42:08 Epoch 101/200, Training Loss: 1.3753
12:42:08 Epoch 102/200, Training Loss: 1.3754
12:42:08 Epoch 103/200, Training Loss: 1.3726
12:42:09 Epoch 104/200, Training Loss: 1.3708
12:42:09 Epoch 105/200, Training Loss: 1.3693
12:42:09 Epoch 106/200, Training Loss: 1.3676
12:42:09 Epoch 107/200, Training Loss: 1.3663
12:42:09 Epoch 108/200, Training Loss: 1.3651
12:42:09 Epoch 109/200, Training Loss: 1.3626
12:42:09 Epoch 110/200, Training Loss: 1.3605
12:42:09 Epoch 111/200, Training Loss: 1.3594
12:42:09 Epoch 112/200, Training Loss: 1.3575
12:42:09 Epoch 113/200, Training Loss: 1.3559
12:42:09 Epoch 114/200, Training Loss: 1.3547
12:42:10 Epoch 115/200, Training Loss: 1.352
12:42:10 Epoch 116/200, Training Loss: 1.3501
12:42:10 Epoch 117/200, Training Loss: 1.3492
12:42:10 Epoch 118/200, Training Loss: 1.3474
12:42:10 Epoch 119/200, Training Loss: 1.3457
12:42:10 Epoch 120/200, Training Loss: 1.3444
12:42:10 Epoch 121/200, Training Loss: 1.342
12:42:10 Epoch 122/200, Training Loss: 1.3394
12:42:10 Epoch 123/200, Training Loss: 1.3384
12:42:10 Epoch 124/200, Training Loss: 1.3362
12:42:10 Epoch 125/200, Training Loss: 1.3342
12:42:10 Epoch 126/200, Training Loss: 1.3338
12:42:11 Epoch 127/200, Training Loss: 1.3315
12:42:11 Epoch 128/200, Training Loss: 1.3286
12:42:11 Epoch 129/200, Training Loss: 1.3269
12:42:11 Epoch 130/200, Training Loss: 1.3249
12:42:11 Epoch 131/200, Training Loss: 1.3235
12:42:11 Epoch 132/200, Training Loss: 1.3233
12:42:11 Epoch 133/200, Training Loss: 1.3203
12:42:11 Epoch 134/200, Training Loss: 1.3184
12:42:11 Epoch 135/200, Training Loss: 1.3166
12:42:11 Epoch 136/200, Training Loss: 1.3137
12:42:11 Epoch 137/200, Training Loss: 1.3115
12:42:12 Epoch 138/200, Training Loss: 1.31
12:42:12 Epoch 139/200, Training Loss: 1.3093
12:42:12 Epoch 140/200, Training Loss: 1.3074
12:42:12 Epoch 141/200, Training Loss: 1.3056
12:42:12 Epoch 142/200, Training Loss: 1.3025
12:42:12 Epoch 143/200, Training Loss: 1.3005
12:42:12 Epoch 144/200, Training Loss: 1.2986
12:42:12 Epoch 145/200, Training Loss: 1.2972
12:42:12 Epoch 146/200, Training Loss: 1.2955
12:42:12 Epoch 147/200, Training Loss: 1.2948
12:42:12 Epoch 148/200, Training Loss: 1.2917
12:42:12 Epoch 149/200, Training Loss: 1.2884
12:42:12 Epoch 150/200, Training Loss: 1.2863
12:42:13 Epoch 151/200, Training Loss: 1.2847
12:42:13 Epoch 152/200, Training Loss: 1.2833
12:42:13 Epoch 153/200, Training Loss: 1.2825
12:42:13 Epoch 154/200, Training Loss: 1.2803
12:42:13 Epoch 155/200, Training Loss: 1.2764
12:42:13 Epoch 156/200, Training Loss: 1.2741
12:42:13 Epoch 157/200, Training Loss: 1.272
12:42:13 Epoch 158/200, Training Loss: 1.2713
12:42:13 Epoch 159/200, Training Loss: 1.2701
12:42:13 Epoch 160/200, Training Loss: 1.2689
12:42:13 Epoch 161/200, Training Loss: 1.2649
12:42:13 Epoch 162/200, Training Loss: 1.2621
12:42:13 Epoch 163/200, Training Loss: 1.26
12:42:14 Epoch 164/200, Training Loss: 1.2587
12:42:14 Epoch 165/200, Training Loss: 1.2582
12:42:14 Epoch 166/200, Training Loss: 1.2563
12:42:14 Epoch 167/200, Training Loss: 1.2535
12:42:14 Epoch 168/200, Training Loss: 1.25
12:42:14 Epoch 169/200, Training Loss: 1.2477
12:42:14 Epoch 170/200, Training Loss: 1.2463
12:42:14 Epoch 171/200, Training Loss: 1.245
12:42:14 Epoch 172/200, Training Loss: 1.2421
12:42:14 Epoch 173/200, Training Loss: 1.2409
12:42:14 Epoch 174/200, Training Loss: 1.2375
12:42:14 Epoch 175/200, Training Loss: 1.2353
12:42:14 Epoch 176/200, Training Loss: 1.2337
12:42:15 Epoch 177/200, Training Loss: 1.2316
12:42:15 Epoch 178/200, Training Loss: 1.2293
12:42:15 Epoch 179/200, Training Loss: 1.2282
12:42:15 Epoch 180/200, Training Loss: 1.225
12:42:15 Epoch 181/200, Training Loss: 1.2228
12:42:15 Epoch 182/200, Training Loss: 1.221
12:42:15 Epoch 183/200, Training Loss: 1.2191
12:42:15 Epoch 184/200, Training Loss: 1.2167
12:42:15 Epoch 185/200, Training Loss: 1.2149
12:42:15 Epoch 186/200, Training Loss: 1.2121
12:42:15 Epoch 187/200, Training Loss: 1.209
12:42:15 Epoch 188/200, Training Loss: 1.2079
12:42:16 Epoch 189/200, Training Loss: 1.2058
12:42:17 Epoch 190/200, Training Loss: 1.2032
12:42:18 Epoch 191/200, Training Loss: 1.2018
12:42:20 Epoch 192/200, Training Loss: 1.199
12:42:21 Epoch 193/200, Training Loss: 1.1972
12:42:22 Epoch 194/200, Training Loss: 1.1949
12:42:23 Epoch 195/200, Training Loss: 1.1914
12:42:24 Epoch 196/200, Training Loss: 1.1889
12:42:25 Epoch 197/200, Training Loss: 1.1877
12:42:26 Epoch 198/200, Training Loss: 1.1867
12:42:27 Epoch 199/200, Training Loss: 1.1857
12:42:29 Epoch 200/200, Training Loss: 1.1823
12:42:29 Model training complete and best model saved --------------------------------

12:42:29 Testing model --------------------------------
12:42:29 Test Loss on this fold: 2.0440
12:42:29 Model testing complete --------------------------------

12:42:29 Fold 5/6: --------------------------------

12:42:29 Training model --------------------------------
12:42:30 Epoch 1/200, Training Loss: 14.3865
12:42:31 Epoch 2/200, Training Loss: 6.1998
12:42:32 Epoch 3/200, Training Loss: 4.1451
12:42:33 Epoch 4/200, Training Loss: 2.9728
12:42:34 Epoch 5/200, Training Loss: 2.9062
12:42:35 Epoch 6/200, Training Loss: 2.5821
12:42:37 Epoch 7/200, Training Loss: 2.1728
12:42:38 Epoch 8/200, Training Loss: 1.9919
12:42:38 Epoch 9/200, Training Loss: 1.8145
12:42:39 Epoch 10/200, Training Loss: 1.7328
12:42:41 Epoch 11/200, Training Loss: 1.6817
12:42:42 Epoch 12/200, Training Loss: 1.6532
12:42:43 Epoch 13/200, Training Loss: 1.6269
12:42:44 Epoch 14/200, Training Loss: 1.6138
12:42:45 Epoch 15/200, Training Loss: 1.5995
12:42:45 Epoch 16/200, Training Loss: 1.593
12:42:45 Epoch 17/200, Training Loss: 1.5837
12:42:45 Epoch 18/200, Training Loss: 1.5791
12:42:45 Epoch 19/200, Training Loss: 1.5726
12:42:45 Epoch 20/200, Training Loss: 1.5688
12:42:45 Epoch 21/200, Training Loss: 1.5638
12:42:45 Epoch 22/200, Training Loss: 1.5604
12:42:46 Epoch 23/200, Training Loss: 1.5565
12:42:46 Epoch 24/200, Training Loss: 1.5536
12:42:46 Epoch 25/200, Training Loss: 1.5502
12:42:46 Epoch 26/200, Training Loss: 1.5475
12:42:46 Epoch 27/200, Training Loss: 1.5445
12:42:46 Epoch 28/200, Training Loss: 1.542
12:42:46 Epoch 29/200, Training Loss: 1.5396
12:42:46 Epoch 30/200, Training Loss: 1.5368
12:42:46 Epoch 31/200, Training Loss: 1.5347
12:42:46 Epoch 32/200, Training Loss: 1.5326
12:42:46 Epoch 33/200, Training Loss: 1.5301
12:42:46 Epoch 34/200, Training Loss: 1.5284
12:42:46 Epoch 35/200, Training Loss: 1.5258
12:42:46 Epoch 36/200, Training Loss: 1.5237
12:42:47 Epoch 37/200, Training Loss: 1.5217
12:42:47 Epoch 38/200, Training Loss: 1.5197
12:42:47 Epoch 39/200, Training Loss: 1.5177
12:42:47 Epoch 40/200, Training Loss: 1.5158
12:42:47 Epoch 41/200, Training Loss: 1.514
12:42:47 Epoch 42/200, Training Loss: 1.5119
12:42:47 Epoch 43/200, Training Loss: 1.5102
12:42:47 Epoch 44/200, Training Loss: 1.5085
12:42:47 Epoch 45/200, Training Loss: 1.5066
12:42:47 Epoch 46/200, Training Loss: 1.5047
12:42:47 Epoch 47/200, Training Loss: 1.503
12:42:47 Epoch 48/200, Training Loss: 1.5018
12:42:47 Epoch 49/200, Training Loss: 1.4998
12:42:47 Epoch 50/200, Training Loss: 1.4985
12:42:47 Epoch 51/200, Training Loss: 1.497
12:42:48 Epoch 52/200, Training Loss: 1.4952
12:42:48 Epoch 53/200, Training Loss: 1.4941
12:42:48 Epoch 54/200, Training Loss: 1.4923
12:42:48 Epoch 55/200, Training Loss: 1.4901
12:42:48 Epoch 56/200, Training Loss: 1.4885
12:42:48 Epoch 57/200, Training Loss: 1.4873
12:42:48 Epoch 58/200, Training Loss: 1.485
12:42:48 Epoch 59/200, Training Loss: 1.484
12:42:48 Epoch 60/200, Training Loss: 1.4823
12:42:48 Epoch 61/200, Training Loss: 1.48
12:42:48 Epoch 62/200, Training Loss: 1.4784
12:42:48 Epoch 63/200, Training Loss: 1.4771
12:42:48 Epoch 64/200, Training Loss: 1.4752
12:42:48 Epoch 65/200, Training Loss: 1.474
12:42:49 Epoch 66/200, Training Loss: 1.4725
12:42:49 Epoch 67/200, Training Loss: 1.4705
12:42:49 Epoch 68/200, Training Loss: 1.4689
12:42:49 Epoch 69/200, Training Loss: 1.4671
12:42:49 Epoch 70/200, Training Loss: 1.4659
12:42:49 Epoch 71/200, Training Loss: 1.4643
12:42:49 Epoch 72/200, Training Loss: 1.4624
12:42:49 Epoch 73/200, Training Loss: 1.4609
12:42:49 Epoch 74/200, Training Loss: 1.4592
12:42:49 Epoch 75/200, Training Loss: 1.4572
12:42:49 Epoch 76/200, Training Loss: 1.456
12:42:49 Epoch 77/200, Training Loss: 1.4549
12:42:49 Epoch 78/200, Training Loss: 1.4525
12:42:50 Epoch 79/200, Training Loss: 1.4512
12:42:50 Epoch 80/200, Training Loss: 1.45
12:42:50 Epoch 81/200, Training Loss: 1.4481
12:42:50 Epoch 82/200, Training Loss: 1.4471
12:42:50 Epoch 83/200, Training Loss: 1.4453
12:42:50 Epoch 84/200, Training Loss: 1.4432
12:42:50 Epoch 85/200, Training Loss: 1.4415
12:42:50 Epoch 86/200, Training Loss: 1.4396
12:42:50 Epoch 87/200, Training Loss: 1.4382
12:42:50 Epoch 88/200, Training Loss: 1.4366
12:42:50 Epoch 89/200, Training Loss: 1.4351
12:42:50 Epoch 90/200, Training Loss: 1.4336
12:42:51 Epoch 91/200, Training Loss: 1.4314
12:42:51 Epoch 92/200, Training Loss: 1.4298
12:42:51 Epoch 93/200, Training Loss: 1.4284
12:42:51 Epoch 94/200, Training Loss: 1.4267
12:42:51 Epoch 95/200, Training Loss: 1.425
12:42:51 Epoch 96/200, Training Loss: 1.4236
12:42:51 Epoch 97/200, Training Loss: 1.4217
12:42:51 Epoch 98/200, Training Loss: 1.4196
12:42:51 Epoch 99/200, Training Loss: 1.4182
12:42:51 Epoch 100/200, Training Loss: 1.4168
12:42:51 Epoch 101/200, Training Loss: 1.4156
12:42:52 Epoch 102/200, Training Loss: 1.4136
12:42:52 Epoch 103/200, Training Loss: 1.4113
12:42:52 Epoch 104/200, Training Loss: 1.4091
12:42:52 Epoch 105/200, Training Loss: 1.4078
12:42:52 Epoch 106/200, Training Loss: 1.4069
12:42:52 Epoch 107/200, Training Loss: 1.4057
12:42:52 Epoch 108/200, Training Loss: 1.4032
12:42:52 Epoch 109/200, Training Loss: 1.401
12:42:52 Epoch 110/200, Training Loss: 1.3988
12:42:52 Epoch 111/200, Training Loss: 1.3969
12:42:52 Epoch 112/200, Training Loss: 1.3961
12:42:52 Epoch 113/200, Training Loss: 1.3949
12:42:53 Epoch 114/200, Training Loss: 1.3947
12:42:53 Epoch 115/200, Training Loss: 1.3917
12:42:53 Epoch 116/200, Training Loss: 1.3898
12:42:53 Epoch 117/200, Training Loss: 1.3877
12:42:53 Epoch 118/200, Training Loss: 1.3858
12:42:53 Epoch 119/200, Training Loss: 1.3838
12:42:53 Epoch 120/200, Training Loss: 1.3817
12:42:53 Epoch 121/200, Training Loss: 1.3799
12:42:53 Epoch 122/200, Training Loss: 1.3784
12:42:53 Epoch 123/200, Training Loss: 1.3764
12:42:53 Epoch 124/200, Training Loss: 1.3744
12:42:53 Epoch 125/200, Training Loss: 1.3727
12:42:54 Epoch 126/200, Training Loss: 1.3706
12:42:54 Epoch 127/200, Training Loss: 1.3687
12:42:54 Epoch 128/200, Training Loss: 1.3668
12:42:54 Epoch 129/200, Training Loss: 1.3653
12:42:54 Epoch 130/200, Training Loss: 1.3636
12:42:54 Epoch 131/200, Training Loss: 1.3618
12:42:54 Epoch 132/200, Training Loss: 1.3594
12:42:54 Epoch 133/200, Training Loss: 1.3573
12:42:54 Epoch 134/200, Training Loss: 1.3553
12:42:54 Epoch 135/200, Training Loss: 1.3535
12:42:54 Epoch 136/200, Training Loss: 1.3524
12:42:55 Epoch 137/200, Training Loss: 1.3509
12:42:55 Epoch 138/200, Training Loss: 1.3484
12:42:55 Epoch 139/200, Training Loss: 1.3464
12:42:55 Epoch 140/200, Training Loss: 1.3444
12:42:55 Epoch 141/200, Training Loss: 1.3424
12:42:55 Epoch 142/200, Training Loss: 1.3402
12:42:55 Epoch 143/200, Training Loss: 1.3389
12:42:55 Epoch 144/200, Training Loss: 1.3376
12:42:55 Epoch 145/200, Training Loss: 1.3349
12:42:55 Epoch 146/200, Training Loss: 1.3327
12:42:55 Epoch 147/200, Training Loss: 1.3305
12:42:55 Epoch 148/200, Training Loss: 1.3283
12:42:56 Epoch 149/200, Training Loss: 1.3258
12:42:56 Epoch 150/200, Training Loss: 1.3253
12:42:56 Epoch 151/200, Training Loss: 1.3228
12:42:56 Epoch 152/200, Training Loss: 1.3211
12:42:56 Epoch 153/200, Training Loss: 1.3193
12:42:56 Epoch 154/200, Training Loss: 1.3163
12:42:56 Epoch 155/200, Training Loss: 1.314
12:42:56 Epoch 156/200, Training Loss: 1.3121
12:42:56 Epoch 157/200, Training Loss: 1.3107
12:42:56 Epoch 158/200, Training Loss: 1.3088
12:42:56 Epoch 159/200, Training Loss: 1.3073
12:42:57 Epoch 160/200, Training Loss: 1.305
12:42:57 Epoch 161/200, Training Loss: 1.3022
12:42:57 Epoch 162/200, Training Loss: 1.3
12:42:57 Epoch 163/200, Training Loss: 1.2982
12:42:57 Epoch 164/200, Training Loss: 1.2964
12:42:57 Epoch 165/200, Training Loss: 1.2953
12:42:57 Epoch 166/200, Training Loss: 1.2934
12:42:57 Epoch 167/200, Training Loss: 1.2901
12:42:57 Epoch 168/200, Training Loss: 1.2874
12:42:57 Epoch 169/200, Training Loss: 1.2854
12:42:57 Epoch 170/200, Training Loss: 1.2836
12:42:57 Epoch 171/200, Training Loss: 1.2817
12:42:58 Epoch 172/200, Training Loss: 1.2795
12:42:58 Epoch 173/200, Training Loss: 1.2786
12:42:58 Epoch 174/200, Training Loss: 1.2751
12:42:58 Epoch 175/200, Training Loss: 1.2727
12:42:58 Epoch 176/200, Training Loss: 1.2713
12:42:58 Epoch 177/200, Training Loss: 1.2692
12:42:58 Epoch 178/200, Training Loss: 1.2681
12:42:58 Epoch 179/200, Training Loss: 1.2659
12:42:58 Epoch 180/200, Training Loss: 1.2621
12:42:58 Epoch 181/200, Training Loss: 1.2598
12:42:58 Epoch 182/200, Training Loss: 1.2585
12:42:58 Epoch 183/200, Training Loss: 1.2565
12:42:59 Epoch 184/200, Training Loss: 1.2551
12:42:59 Epoch 185/200, Training Loss: 1.2531
12:42:59 Epoch 186/200, Training Loss: 1.2492
12:42:59 Epoch 187/200, Training Loss: 1.2469
12:42:59 Epoch 188/200, Training Loss: 1.2453
12:42:59 Epoch 189/200, Training Loss: 1.2434
12:42:59 Epoch 190/200, Training Loss: 1.2418
12:42:59 Epoch 191/200, Training Loss: 1.241
12:42:59 Epoch 192/200, Training Loss: 1.2372
12:42:59 Epoch 193/200, Training Loss: 1.2341
12:42:59 Epoch 194/200, Training Loss: 1.2329
12:42:59 Epoch 195/200, Training Loss: 1.2315
12:43:00 Epoch 196/200, Training Loss: 1.2289
12:43:00 Epoch 197/200, Training Loss: 1.2276
12:43:00 Epoch 198/200, Training Loss: 1.2249
12:43:00 Epoch 199/200, Training Loss: 1.2218
12:43:00 Epoch 200/200, Training Loss: 1.2194
12:43:00 Model training complete and best model saved --------------------------------

12:43:00 Testing model --------------------------------
12:43:00 Test Loss on this fold: 1.9037
12:43:00 Model testing complete --------------------------------

12:43:00 Fold 6/6: --------------------------------

12:43:00 Training model --------------------------------
12:43:00 Epoch 1/200, Training Loss: 14.4819
12:43:00 Epoch 2/200, Training Loss: 6.2133
12:43:00 Epoch 3/200, Training Loss: 4.0688
12:43:00 Epoch 4/200, Training Loss: 3.0192
12:43:00 Epoch 5/200, Training Loss: 2.8645
12:43:00 Epoch 6/200, Training Loss: 2.3861
12:43:01 Epoch 7/200, Training Loss: 2.1648
12:43:01 Epoch 8/200, Training Loss: 1.954
12:43:01 Epoch 9/200, Training Loss: 1.8088
12:43:01 Epoch 10/200, Training Loss: 1.7417
12:43:01 Epoch 11/200, Training Loss: 1.6914
12:43:01 Epoch 12/200, Training Loss: 1.6699
12:43:01 Epoch 13/200, Training Loss: 1.6339
12:43:01 Epoch 14/200, Training Loss: 1.6233
12:43:01 Epoch 15/200, Training Loss: 1.6057
12:43:01 Epoch 16/200, Training Loss: 1.5999
12:43:01 Epoch 17/200, Training Loss: 1.5878
12:43:02 Epoch 18/200, Training Loss: 1.5826
12:43:02 Epoch 19/200, Training Loss: 1.5764
12:43:02 Epoch 20/200, Training Loss: 1.571
12:43:02 Epoch 21/200, Training Loss: 1.5669
12:43:02 Epoch 22/200, Training Loss: 1.5625
12:43:02 Epoch 23/200, Training Loss: 1.5591
12:43:02 Epoch 24/200, Training Loss: 1.5552
12:43:02 Epoch 25/200, Training Loss: 1.5524
12:43:02 Epoch 26/200, Training Loss: 1.5494
12:43:02 Epoch 27/200, Training Loss: 1.5468
12:43:02 Epoch 28/200, Training Loss: 1.544
12:43:03 Epoch 29/200, Training Loss: 1.5413
12:43:03 Epoch 30/200, Training Loss: 1.5391
12:43:03 Epoch 31/200, Training Loss: 1.5364
12:43:03 Epoch 32/200, Training Loss: 1.5339
12:43:03 Epoch 33/200, Training Loss: 1.5315
12:43:03 Epoch 34/200, Training Loss: 1.5292
12:43:03 Epoch 35/200, Training Loss: 1.527
12:43:03 Epoch 36/200, Training Loss: 1.525
12:43:03 Epoch 37/200, Training Loss: 1.5226
12:43:03 Epoch 38/200, Training Loss: 1.521
12:43:03 Epoch 39/200, Training Loss: 1.5191
12:43:04 Epoch 40/200, Training Loss: 1.5163
12:43:04 Epoch 41/200, Training Loss: 1.5148
12:43:04 Epoch 42/200, Training Loss: 1.5125
12:43:04 Epoch 43/200, Training Loss: 1.5101
12:43:04 Epoch 44/200, Training Loss: 1.5083
12:43:04 Epoch 45/200, Training Loss: 1.5061
12:43:04 Epoch 46/200, Training Loss: 1.5044
12:43:04 Epoch 47/200, Training Loss: 1.5021
12:43:04 Epoch 48/200, Training Loss: 1.4999
12:43:04 Epoch 49/200, Training Loss: 1.4985
12:43:04 Epoch 50/200, Training Loss: 1.4961
12:43:04 Epoch 51/200, Training Loss: 1.4936
12:43:04 Epoch 52/200, Training Loss: 1.492
12:43:05 Epoch 53/200, Training Loss: 1.4901
12:43:05 Epoch 54/200, Training Loss: 1.4885
12:43:05 Epoch 55/200, Training Loss: 1.4869
12:43:05 Epoch 56/200, Training Loss: 1.4848
12:43:05 Epoch 57/200, Training Loss: 1.4826
12:43:05 Epoch 58/200, Training Loss: 1.4808
12:43:05 Epoch 59/200, Training Loss: 1.4786
12:43:05 Epoch 60/200, Training Loss: 1.4771
12:43:05 Epoch 61/200, Training Loss: 1.4757
12:43:05 Epoch 62/200, Training Loss: 1.4732
12:43:05 Epoch 63/200, Training Loss: 1.4716
12:43:05 Epoch 64/200, Training Loss: 1.4692
12:43:05 Epoch 65/200, Training Loss: 1.4671
12:43:06 Epoch 66/200, Training Loss: 1.4655
12:43:06 Epoch 67/200, Training Loss: 1.4638
12:43:06 Epoch 68/200, Training Loss: 1.4618
12:43:06 Epoch 69/200, Training Loss: 1.4606
12:43:06 Epoch 70/200, Training Loss: 1.4591
12:43:06 Epoch 71/200, Training Loss: 1.4564
12:43:07 Epoch 72/200, Training Loss: 1.4546
12:43:08 Epoch 73/200, Training Loss: 1.4529
12:43:10 Epoch 74/200, Training Loss: 1.4513
12:43:11 Epoch 75/200, Training Loss: 1.4495
12:43:12 Epoch 76/200, Training Loss: 1.4478
12:43:13 Epoch 77/200, Training Loss: 1.4453
12:43:14 Epoch 78/200, Training Loss: 1.4436
12:43:15 Epoch 79/200, Training Loss: 1.4421
12:43:16 Epoch 80/200, Training Loss: 1.4398
12:43:17 Epoch 81/200, Training Loss: 1.4382
12:43:19 Epoch 82/200, Training Loss: 1.4362
12:43:20 Epoch 83/200, Training Loss: 1.4346
12:43:21 Epoch 84/200, Training Loss: 1.4327
12:43:22 Epoch 85/200, Training Loss: 1.4307
12:43:23 Epoch 86/200, Training Loss: 1.4286
12:43:24 Epoch 87/200, Training Loss: 1.4268
12:43:25 Epoch 88/200, Training Loss: 1.4249
12:43:26 Epoch 89/200, Training Loss: 1.4232
12:43:27 Epoch 90/200, Training Loss: 1.4216
12:43:29 Epoch 91/200, Training Loss: 1.4195
12:43:30 Epoch 92/200, Training Loss: 1.4175
12:43:31 Epoch 93/200, Training Loss: 1.4151
12:43:32 Epoch 94/200, Training Loss: 1.4128
12:43:33 Epoch 95/200, Training Loss: 1.4113
12:43:33 Epoch 96/200, Training Loss: 1.4096
12:43:34 Epoch 97/200, Training Loss: 1.4076
12:43:34 Epoch 98/200, Training Loss: 1.4065
12:43:35 Epoch 99/200, Training Loss: 1.4039
12:43:35 Epoch 100/200, Training Loss: 1.4018
12:43:36 Epoch 101/200, Training Loss: 1.399
12:43:36 Epoch 102/200, Training Loss: 1.3972
12:43:37 Epoch 103/200, Training Loss: 1.3946
12:43:37 Epoch 104/200, Training Loss: 1.3934
12:43:37 Epoch 105/200, Training Loss: 1.392
12:43:38 Epoch 106/200, Training Loss: 1.3908
12:43:38 Epoch 107/200, Training Loss: 1.3877
12:43:39 Epoch 108/200, Training Loss: 1.3852
12:43:39 Epoch 109/200, Training Loss: 1.3828
12:43:39 Epoch 110/200, Training Loss: 1.3818
12:43:39 Epoch 111/200, Training Loss: 1.3799
12:43:40 Epoch 112/200, Training Loss: 1.3774
12:43:40 Epoch 113/200, Training Loss: 1.3764
12:43:41 Epoch 114/200, Training Loss: 1.3729
12:43:41 Epoch 115/200, Training Loss: 1.3706
12:43:41 Epoch 116/200, Training Loss: 1.3691
12:43:41 Epoch 117/200, Training Loss: 1.3674
12:43:41 Epoch 118/200, Training Loss: 1.3661
12:43:42 Epoch 119/200, Training Loss: 1.3639
12:43:42 Epoch 120/200, Training Loss: 1.3606
12:43:42 Epoch 121/200, Training Loss: 1.3581
12:43:42 Epoch 122/200, Training Loss: 1.3566
12:43:42 Epoch 123/200, Training Loss: 1.3545
12:43:42 Epoch 124/200, Training Loss: 1.3523
12:43:42 Epoch 125/200, Training Loss: 1.3511
12:43:42 Epoch 126/200, Training Loss: 1.3483
12:43:42 Epoch 127/200, Training Loss: 1.3461
12:43:42 Epoch 128/200, Training Loss: 1.344
12:43:42 Epoch 129/200, Training Loss: 1.3413
12:43:42 Epoch 130/200, Training Loss: 1.3394
12:43:42 Epoch 131/200, Training Loss: 1.3387
12:43:43 Epoch 132/200, Training Loss: 1.3354
12:43:43 Epoch 133/200, Training Loss: 1.3333
12:43:43 Epoch 134/200, Training Loss: 1.3308
12:43:43 Epoch 135/200, Training Loss: 1.3282
12:43:43 Epoch 136/200, Training Loss: 1.3259
12:43:43 Epoch 137/200, Training Loss: 1.3247
12:43:43 Epoch 138/200, Training Loss: 1.3221
12:43:43 Epoch 139/200, Training Loss: 1.3201
12:43:43 Epoch 140/200, Training Loss: 1.3176
12:43:43 Epoch 141/200, Training Loss: 1.3145
12:43:43 Epoch 142/200, Training Loss: 1.3122
12:43:43 Epoch 143/200, Training Loss: 1.3108
12:43:43 Epoch 144/200, Training Loss: 1.3084
12:43:44 Epoch 145/200, Training Loss: 1.3075
12:43:44 Epoch 146/200, Training Loss: 1.3046
12:43:44 Epoch 147/200, Training Loss: 1.3009
12:43:44 Epoch 148/200, Training Loss: 1.2987
12:43:44 Epoch 149/200, Training Loss: 1.2969
12:43:44 Epoch 150/200, Training Loss: 1.2951
12:43:44 Epoch 151/200, Training Loss: 1.2939
12:43:44 Epoch 152/200, Training Loss: 1.2905
12:43:44 Epoch 153/200, Training Loss: 1.287
12:43:44 Epoch 154/200, Training Loss: 1.2841
12:43:44 Epoch 155/200, Training Loss: 1.2819
12:43:44 Epoch 156/200, Training Loss: 1.2802
12:43:45 Epoch 157/200, Training Loss: 1.2795
12:43:45 Epoch 158/200, Training Loss: 1.2772
12:43:45 Epoch 159/200, Training Loss: 1.2746
12:43:45 Epoch 160/200, Training Loss: 1.2718
12:43:45 Epoch 161/200, Training Loss: 1.2687
12:43:45 Epoch 162/200, Training Loss: 1.266
12:43:45 Epoch 163/200, Training Loss: 1.2643
12:43:45 Epoch 164/200, Training Loss: 1.2634
12:43:45 Epoch 165/200, Training Loss: 1.2617
12:43:45 Epoch 166/200, Training Loss: 1.2595
12:43:45 Epoch 167/200, Training Loss: 1.2555
12:43:45 Epoch 168/200, Training Loss: 1.252
12:43:45 Epoch 169/200, Training Loss: 1.2492
12:43:45 Epoch 170/200, Training Loss: 1.2478
12:43:46 Epoch 171/200, Training Loss: 1.2465
12:43:46 Epoch 172/200, Training Loss: 1.2449
12:43:46 Epoch 173/200, Training Loss: 1.2421
12:43:46 Epoch 174/200, Training Loss: 1.2378
12:43:46 Epoch 175/200, Training Loss: 1.235
12:43:46 Epoch 176/200, Training Loss: 1.233
12:43:46 Epoch 177/200, Training Loss: 1.2312
12:43:46 Epoch 178/200, Training Loss: 1.2302
12:43:46 Epoch 179/200, Training Loss: 1.2275
12:43:46 Epoch 180/200, Training Loss: 1.2234
12:43:47 Epoch 181/200, Training Loss: 1.221
12:43:47 Epoch 182/200, Training Loss: 1.2192
12:43:47 Epoch 183/200, Training Loss: 1.2177
12:43:47 Epoch 184/200, Training Loss: 1.2162
12:43:47 Epoch 185/200, Training Loss: 1.2127
12:43:47 Epoch 186/200, Training Loss: 1.2094
12:43:47 Epoch 187/200, Training Loss: 1.2078
12:43:47 Epoch 188/200, Training Loss: 1.2053
12:43:47 Epoch 189/200, Training Loss: 1.2031
12:43:47 Epoch 190/200, Training Loss: 1.2013
12:43:47 Epoch 191/200, Training Loss: 1.1975
12:43:48 Epoch 192/200, Training Loss: 1.1944
12:43:48 Epoch 193/200, Training Loss: 1.1925
12:43:48 Epoch 194/200, Training Loss: 1.1903
12:43:48 Epoch 195/200, Training Loss: 1.1885
12:43:48 Epoch 196/200, Training Loss: 1.1869
12:43:48 Epoch 197/200, Training Loss: 1.1828
12:43:48 Epoch 198/200, Training Loss: 1.1813
12:43:48 Epoch 199/200, Training Loss: 1.178
12:43:48 Epoch 200/200, Training Loss: 1.1753
12:43:48 Model training complete and best model saved --------------------------------

12:43:48 Testing model --------------------------------
12:43:48 Test Loss on this fold: 1.7693
12:43:48 Best model updated from this fold based on test loss.
12:43:48 Model testing complete --------------------------------

12:43:48 Best Fold: 6
12:43:48 Best Fold Training Indices: [0 1 2 4 5]
12:43:48 Best Fold Testing Indices: [3]
12:43:48 Best Fold Test Loss: 1.7692867517471313
