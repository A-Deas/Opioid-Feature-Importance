09:59:18 Training model --------------------------------

09:59:20 Epoch 1/500, Training Loss: 10.7656
09:59:20 Epoch 1/500, Validation Loss: 45.4896

09:59:20 Epoch 2/500, Training Loss: 13.6298
09:59:20 Epoch 2/500, Validation Loss: 10.9887

09:59:20 Epoch 3/500, Training Loss: 11.9175
09:59:20 Epoch 3/500, Validation Loss: 9.2431

09:59:21 Epoch 4/500, Training Loss: 6.1829
09:59:21 Epoch 4/500, Validation Loss: 5.5887

09:59:21 Epoch 5/500, Training Loss: 7.374
09:59:21 Epoch 5/500, Validation Loss: 5.0365

09:59:22 Epoch 6/500, Training Loss: 6.2799
09:59:22 Epoch 6/500, Validation Loss: 4.8877

09:59:22 Epoch 7/500, Training Loss: 5.7554
09:59:22 Epoch 7/500, Validation Loss: 4.7719

09:59:22 Epoch 8/500, Training Loss: 6.3917
09:59:22 Epoch 8/500, Validation Loss: 4.7952

09:59:23 Epoch 9/500, Training Loss: 5.7094
09:59:23 Epoch 9/500, Validation Loss: 4.6414

09:59:23 Epoch 10/500, Training Loss: 5.7969
09:59:23 Epoch 10/500, Validation Loss: 4.6571

09:59:23 Epoch 11/500, Training Loss: 5.6793
09:59:23 Epoch 11/500, Validation Loss: 4.6608

09:59:24 Epoch 12/500, Training Loss: 5.6633
09:59:24 Epoch 12/500, Validation Loss: 4.6765

09:59:24 Epoch 13/500, Training Loss: 5.5898
09:59:24 Epoch 13/500, Validation Loss: 4.6488

09:59:24 Epoch 14/500, Training Loss: 5.6124
09:59:24 Epoch 14/500, Validation Loss: 4.6493

09:59:25 Epoch 15/500, Training Loss: 5.585
09:59:25 Epoch 15/500, Validation Loss: 4.6455

09:59:25 Epoch 16/500, Training Loss: 5.5808
09:59:25 Epoch 16/500, Validation Loss: 4.6459

09:59:25 Epoch 17/500, Training Loss: 5.5642
09:59:25 Epoch 17/500, Validation Loss: 4.6408

09:59:26 Epoch 18/500, Training Loss: 5.5658
09:59:26 Epoch 18/500, Validation Loss: 4.6404

09:59:26 Epoch 19/500, Training Loss: 5.5565
09:59:26 Epoch 19/500, Validation Loss: 4.6368

09:59:26 Epoch 20/500, Training Loss: 5.553
09:59:26 Epoch 20/500, Validation Loss: 4.6359

09:59:27 Epoch 21/500, Training Loss: 5.5471
09:59:27 Epoch 21/500, Validation Loss: 4.6331

09:59:27 Epoch 22/500, Training Loss: 5.5448
09:59:27 Epoch 22/500, Validation Loss: 4.6317

09:59:27 Epoch 23/500, Training Loss: 5.5392
09:59:27 Epoch 23/500, Validation Loss: 4.63

09:59:28 Epoch 24/500, Training Loss: 5.537
09:59:28 Epoch 24/500, Validation Loss: 4.6279

09:59:28 Epoch 25/500, Training Loss: 5.5321
09:59:28 Epoch 25/500, Validation Loss: 4.6276

09:59:28 Epoch 26/500, Training Loss: 5.5291
09:59:28 Epoch 26/500, Validation Loss: 4.625

09:59:29 Epoch 27/500, Training Loss: 5.5253
09:59:29 Epoch 27/500, Validation Loss: 4.6248

09:59:29 Epoch 28/500, Training Loss: 5.5215
09:59:29 Epoch 28/500, Validation Loss: 4.6237

09:59:29 Epoch 29/500, Training Loss: 5.518
09:59:29 Epoch 29/500, Validation Loss: 4.6227

09:59:30 Epoch 30/500, Training Loss: 5.5146
09:59:30 Epoch 30/500, Validation Loss: 4.621

09:59:30 Epoch 31/500, Training Loss: 5.5104
09:59:30 Epoch 31/500, Validation Loss: 4.6196

09:59:31 Epoch 32/500, Training Loss: 5.5069
09:59:31 Epoch 32/500, Validation Loss: 4.618

09:59:31 Epoch 33/500, Training Loss: 5.5036
09:59:31 Epoch 33/500, Validation Loss: 4.6171

09:59:31 Epoch 34/500, Training Loss: 5.4995
09:59:31 Epoch 34/500, Validation Loss: 4.6164

09:59:32 Epoch 35/500, Training Loss: 5.4957
09:59:32 Epoch 35/500, Validation Loss: 4.615

09:59:32 Epoch 36/500, Training Loss: 5.4923
09:59:32 Epoch 36/500, Validation Loss: 4.6143

09:59:32 Epoch 37/500, Training Loss: 5.4882
09:59:32 Epoch 37/500, Validation Loss: 4.613

09:59:33 Epoch 38/500, Training Loss: 5.4842
09:59:33 Epoch 38/500, Validation Loss: 4.6121

09:59:33 Epoch 39/500, Training Loss: 5.4806
09:59:33 Epoch 39/500, Validation Loss: 4.6108

09:59:33 Epoch 40/500, Training Loss: 5.477
09:59:33 Epoch 40/500, Validation Loss: 4.61

09:59:34 Epoch 41/500, Training Loss: 5.4723
09:59:34 Epoch 41/500, Validation Loss: 4.6096

09:59:34 Epoch 42/500, Training Loss: 5.469
09:59:34 Epoch 42/500, Validation Loss: 4.6094

09:59:34 Epoch 43/500, Training Loss: 5.4652
09:59:34 Epoch 43/500, Validation Loss: 4.6096

09:59:35 Epoch 44/500, Training Loss: 5.4606
09:59:35 Epoch 44/500, Validation Loss: 4.6081

09:59:35 Epoch 45/500, Training Loss: 5.4575
09:59:35 Epoch 45/500, Validation Loss: 4.6063

09:59:35 Epoch 46/500, Training Loss: 5.4518
09:59:35 Epoch 46/500, Validation Loss: 4.6052

09:59:36 Epoch 47/500, Training Loss: 5.449
09:59:36 Epoch 47/500, Validation Loss: 4.6047

09:59:36 Epoch 48/500, Training Loss: 5.4444
09:59:36 Epoch 48/500, Validation Loss: 4.6045

09:59:36 Epoch 49/500, Training Loss: 5.4405
09:59:36 Epoch 49/500, Validation Loss: 4.6038

09:59:37 Epoch 50/500, Training Loss: 5.4362
09:59:37 Epoch 50/500, Validation Loss: 4.6037

09:59:37 Epoch 51/500, Training Loss: 5.4316
09:59:37 Epoch 51/500, Validation Loss: 4.6024

09:59:37 Epoch 52/500, Training Loss: 5.4284
09:59:37 Epoch 52/500, Validation Loss: 4.6012

09:59:38 Epoch 53/500, Training Loss: 5.4231
09:59:38 Epoch 53/500, Validation Loss: 4.6008

09:59:38 Epoch 54/500, Training Loss: 5.4194
09:59:38 Epoch 54/500, Validation Loss: 4.6006

09:59:38 Epoch 55/500, Training Loss: 5.4145
09:59:38 Epoch 55/500, Validation Loss: 4.5988

09:59:39 Epoch 56/500, Training Loss: 5.4107
09:59:39 Epoch 56/500, Validation Loss: 4.5983

09:59:39 Epoch 57/500, Training Loss: 5.4057
09:59:39 Epoch 57/500, Validation Loss: 4.5978

09:59:39 Epoch 58/500, Training Loss: 5.4024
09:59:39 Epoch 58/500, Validation Loss: 4.5962

09:59:40 Epoch 59/500, Training Loss: 5.3965
09:59:40 Epoch 59/500, Validation Loss: 4.5959

09:59:40 Epoch 60/500, Training Loss: 5.3927
09:59:40 Epoch 60/500, Validation Loss: 4.5954

09:59:40 Epoch 61/500, Training Loss: 5.3873
09:59:40 Epoch 61/500, Validation Loss: 4.5952

09:59:41 Epoch 62/500, Training Loss: 5.3842
09:59:41 Epoch 62/500, Validation Loss: 4.5939

09:59:41 Epoch 63/500, Training Loss: 5.3778
09:59:41 Epoch 63/500, Validation Loss: 4.5932

09:59:41 Epoch 64/500, Training Loss: 5.3741
09:59:41 Epoch 64/500, Validation Loss: 4.5922

09:59:42 Epoch 65/500, Training Loss: 5.3688
09:59:42 Epoch 65/500, Validation Loss: 4.592

09:59:42 Epoch 66/500, Training Loss: 5.3654
09:59:42 Epoch 66/500, Validation Loss: 4.5925

09:59:42 Epoch 67/500, Training Loss: 5.3587
09:59:42 Epoch 67/500, Validation Loss: 4.5912

09:59:43 Epoch 68/500, Training Loss: 5.3547
09:59:43 Epoch 68/500, Validation Loss: 4.5902

09:59:43 Epoch 69/500, Training Loss: 5.3492
09:59:43 Epoch 69/500, Validation Loss: 4.5902

09:59:43 Epoch 70/500, Training Loss: 5.3455
09:59:43 Epoch 70/500, Validation Loss: 4.5904

09:59:44 Epoch 71/500, Training Loss: 5.3386
09:59:44 Epoch 71/500, Validation Loss: 4.5893

09:59:44 Epoch 72/500, Training Loss: 5.3354
09:59:44 Epoch 72/500, Validation Loss: 4.5907

09:59:44 Epoch 73/500, Training Loss: 5.3285
09:59:44 Epoch 73/500, Validation Loss: 4.5906

09:59:45 Epoch 74/500, Training Loss: 5.3249
09:59:45 Epoch 74/500, Validation Loss: 4.5907

09:59:45 Epoch 75/500, Training Loss: 5.3177
09:59:45 Epoch 75/500, Validation Loss: 4.5895

09:59:45 Epoch 76/500, Training Loss: 5.315
09:59:45 Epoch 76/500, Validation Loss: 4.5901

09:59:46 Epoch 77/500, Training Loss: 5.3073
09:59:46 Epoch 77/500, Validation Loss: 4.5894

09:59:46 Epoch 78/500, Training Loss: 5.3036
09:59:46 Epoch 78/500, Validation Loss: 4.5903

09:59:46 Epoch 79/500, Training Loss: 5.2962
09:59:46 Epoch 79/500, Validation Loss: 4.5895

09:59:47 Epoch 80/500, Training Loss: 5.2926
09:59:47 Epoch 80/500, Validation Loss: 4.5897

09:59:47 Epoch 81/500, Training Loss: 5.2852
09:59:47 Epoch 81/500, Validation Loss: 4.5895

09:59:47 Early stopping at epoch 81 with best validation loss: 4.5893
09:59:47 Model training complete and saved --------------------------------

09:59:47 Testing model --------------------------------

09:59:47 Test loss for 2022 predictions: 12.9562
09:59:47 Model testing complete --------------------------------

